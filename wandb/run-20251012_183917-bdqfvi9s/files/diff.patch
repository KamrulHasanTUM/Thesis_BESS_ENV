warning: in the working copy of 'training.py', LF will be replaced by CRLF the next time Git touches it
diff --git a/ENV_BESS_main.py b/ENV_BESS_main.py
index d6b876f..91cc737 100644
--- a/ENV_BESS_main.py
+++ b/ENV_BESS_main.py
@@ -29,6 +29,8 @@ import warnings
 import numpy as np
 
 import env_helpers as helpers
+# Add this import to use the function from training.py
+from training import setup_environment, create_model, train_model, get_logdir, train_model_with_wandb
 
 warnings.simplefilter(action='ignore', category=FutureWarning)
 
@@ -54,14 +56,14 @@ class ENV_BESS(gymnasium.Env):
                  exp_code=None,
 
                  # ========== BESS parameters (new) ==========
-                 num_bess=5,
-                 bess_capacity_mwh=50.0,
-                 bess_power_mw=50.0,
-                 soc_min=0.1,
-                 soc_max=0.9,
-                 initial_soc=0.5,
-                 efficiency=0.9,
-                 time_step_hours=1.0
+                 num_bess=None,
+                 bess_capacity_mwh=None,
+                 bess_power_mw=None,
+                 soc_min=None,
+                 soc_max=None,
+                 initial_soc=None,
+                 efficiency=None,
+                 time_step_hours=None
                  ):
         """
         Initialize the BESS environment with network and training parameters.
@@ -102,6 +104,20 @@ class ENV_BESS(gymnasium.Env):
                                              nan_vm_pu_penalty, 0.0, penalty_scalar)
         helpers.initialize_state_variables(self)
 
+        # Load BESS defaults from config if not provided
+        from config import create_bess_env_config
+        bess_defaults = create_bess_env_config({'exp_code': 'default'})
+        
+        # Use provided values or fall back to config defaults
+        num_bess = num_bess if num_bess is not None else bess_defaults['num_bess']
+        bess_capacity_mwh = bess_capacity_mwh if bess_capacity_mwh is not None else bess_defaults['bess_capacity_mwh']
+        bess_power_mw = bess_power_mw if bess_power_mw is not None else bess_defaults['bess_power_mw']
+        soc_min = soc_min if soc_min is not None else bess_defaults['soc_min']
+        soc_max = soc_max if soc_max is not None else bess_defaults['soc_max']
+        initial_soc = initial_soc if initial_soc is not None else bess_defaults['initial_soc']
+        efficiency = efficiency if efficiency is not None else bess_defaults['efficiency']
+        time_step_hours = time_step_hours if time_step_hours is not None else bess_defaults['time_step_hours']
+
         # Initialize BESS parameters
         # These will be used by BESS-specific helper functions (initialize_bess_state, apply_bess_action, etc.)
         self.num_bess = num_bess
@@ -279,21 +295,21 @@ from utils import TQDMProgressCallback
 
 def main():
     init_meta = load_config()
-    env_config = create_bess_env_config(init_meta) 
+    env_config = create_bess_env_config(init_meta)
     training_config = create_training_config(init_meta)
-
-    # Setup environment and logging
+    
     env = setup_environment(ENV_BESS, env_config)
     logdir = get_logdir()
-
-    # Save metadata and create model
+    
     save_training_metadata(training_config, logdir)
     model = create_model(env, training_config, logdir)
-
-    # Setup callbacks and train
-    tqdm_callback = TQDMProgressCallback(total_timesteps=training_config['total_timesteps'])
-    train_model(model, training_config, tqdm_callback)
-
+    
+    # OLD (delete these 2 lines):
+    # tqdm_callback = TQDMProgressCallback(total_timesteps=training_config['total_timesteps'])
+    # train_model(model, training_config, tqdm_callback)
+    
+    # NEW (add this 1 line):
+    train_model_with_wandb(model, training_config, env_config)
 
 if __name__ == "__main__":
-    main()
+    main()
\ No newline at end of file
diff --git a/config.py b/config.py
index 9f2bba2..e060e50 100644
--- a/config.py
+++ b/config.py
@@ -112,7 +112,7 @@ def create_training_config(init_meta):
         'clip_range': 0.2,
         'ent_coef': 0.01,
         'max_grad_norm': 0.5,
-        'total_timesteps': 1_000_000,
+        'total_timesteps': 10_000,
         'initial_learning_rate': 0.0003,
         'exp_id': init_meta["exp_id"],
         'exp_code': init_meta["exp_code"],
diff --git a/training.py b/training.py
index 9ad47d0..e61eef8 100644
--- a/training.py
+++ b/training.py
@@ -7,6 +7,8 @@ Handles environment setup, PPO model creation, and training execution with callb
 
 import os
 import datetime
+from wandb_integration import WandbCallback, init_wandb_run
+import wandb
 from stable_baselines3 import PPO
 from stable_baselines3.common.monitor import Monitor
 from stable_baselines3.common.vec_env import DummyVecEnv
@@ -87,6 +89,27 @@ def train_model(model, training_config, tqdm_callback):
         model.save(f"{training_config['exp_code']}")
         print("Model saved successfully!")
 
+def train_model_with_wandb(model, training_config, env_config):
+    """Train model with W&B tracking."""
+    full_config = {**env_config, **training_config}
+    run = init_wandb_run(full_config, project_name="thesis-bess-env")
+    
+    wandb_callback = WandbCallback(log_freq=10)
+    
+    try:
+        model.learn(
+            total_timesteps=training_config['total_timesteps'],
+            callback=wandb_callback,
+            progress_bar=True
+        )
+        
+        model.save("final_model")
+        artifact = wandb.Artifact('bess-ppo-model', type='model')
+        artifact.add_file('final_model.zip')
+        run.log_artifact(artifact)
+    finally:
+        run.finish()
+
 
 def get_logdir():
     """
